{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T03:58:24.327072Z",
     "start_time": "2025-05-03T03:58:19.350938Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms   # demo dataset + preprocessing\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44bdee52c640a1",
   "metadata": {},
   "source": [
    "2. Define the network\n",
    "\n",
    "+ nn.Sequential stitches the layers together in order.\n",
    "+ Each hidden layer is Linear → ReLU (→ Dropout).\n",
    "+ No softmax in forward; we’ll apply it in the loss (CrossEntropyLoss expects raw logits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2892a0c7dd6ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T03:59:29.372013Z",
     "start_time": "2025-05-03T03:59:29.364749Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: list[int], output_dim: int,\n",
    "                 dropout_p: float = 0.0):\n",
    "        \"\"\"\n",
    "        input_dim   - total number of input features (e.g. 28×28 = 784 for MNIST)\n",
    "        hidden_dims - list like [256, 128] → two hidden layers with those sizes\n",
    "        output_dim  - number of output units (10 for MNIST digits 0‑9)\n",
    "        dropout_p   - dropout probability (0 → no dropout)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            # add hidden layer\n",
    "            layers += [\n",
    "                nn.Linear(prev_dim, h),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "            # add dropout layer if dropout_p > 0\n",
    "            if dropout_p > 0:\n",
    "                layers.append(nn.Dropout(dropout_p))\n",
    "            prev_dim = h\n",
    "        # add final layer\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))  # output layer\n",
    "        print(f\"layers sizes: {layers.__len__()}\")\n",
    "        print(f\"layers: {layers}\")\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x comes in with shape [batch_size, input_dim]\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07ca58",
   "metadata": {},
   "source": [
    "3 . Prepare data (MNIST demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cebdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set length: 60000\n",
      "train_set data shape: torch.Size([60000, 28, 28])\n",
      "test_set data shape: torch.Size([10000, 28, 28])\n",
      "train_set targets shape: torch.Size([60000])\n",
      "test_set targets shape: torch.Size([10000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print first row label: 5\n",
      "train_loader shape: 60000\n",
      "test_loader shape: 10000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),               # converts H×W×C in [0,1]\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # flatten to 784‑vector\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(root=\"data\", train=True,  download=True, transform=transform)\n",
    "test_set  = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "print(f\"train_set data shape: {train_set.data.shape}\")\n",
    "print(f\"test_set data shape: {test_set.data.shape}\")\n",
    "\n",
    "print(f\"train_set targets shape: {train_set.targets.shape}\")\n",
    "print(f\"test_set targets shape: {test_set.targets.shape}\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(train_set.data[0])\n",
    "plt.axis('off')  # Turn off axis labels and ticks\n",
    "plt.show()\n",
    "print(f\"Print first row label: {train_set.targets[0]}\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"train_loader shape: {len(train_loader.dataset.data)}\")\n",
    "print(f\"test_loader shape: {len(test_loader.dataset.data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee50be",
   "metadata": {},
   "source": [
    "4 . Instantiate network, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16796596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers sizes: 7\n",
      "layers: [Linear(in_features=784, out_features=256, bias=True), ReLU(), Dropout(p=0.2, inplace=False), Linear(in_features=256, out_features=128, bias=True), ReLU(), Dropout(p=0.2, inplace=False), Linear(in_features=128, out_features=10, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "mlp_model = MLP(input_dim=784, hidden_dims=[256, 128], output_dim=10, dropout_p=0.2).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()                 # handles logits + integer labels\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=1e-3) # any torch optimizer works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca1bbb",
   "metadata": {},
   "source": [
    "5 . Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd39553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/5 - train loss: 0.3882\n",
      "Epoch  2/5 - train loss: 0.1538\n",
      "Epoch  3/5 - train loss: 0.1095\n",
      "Epoch  4/5 - train loss: 0.0867\n",
      "Epoch  5/5 - train loss: 0.0710\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    mlp_model.train()\n",
    "    running_loss = 0.0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        # optimizer.zero_grad() - clear gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        # mlp_model(X) - forward pass\n",
    "        logits = mlp_model(X)  # forward\n",
    "        # criterion(logits, y) - compute loss\n",
    "        loss = criterion(logits, y)\n",
    "        # loss.backward() - compute gradients\n",
    "        loss.backward()   # backward\n",
    "        # optimizer.step() - update weights\n",
    "        optimizer.step()  # update weights\n",
    "        # running_loss += loss.item() * X.size(0) - accumulate loss\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} - train loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbaa7e",
   "metadata": {},
   "source": [
    "6 . Evaluation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a585b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            preds = model(X).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.90%\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(mlp_model, test_loader)\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc3832",
   "metadata": {},
   "source": [
    "7 . Inference on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a499cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 7\n"
     ]
    }
   ],
   "source": [
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    sample, _ = test_set[0]             # first image, ignore label here\n",
    "    sample = sample.to(DEVICE)\n",
    "    pred_digit = mlp_model(sample).argmax().item()\n",
    "print(\"Predicted digit:\", pred_digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
